---
- name: Install K8s components
  hosts: all
  become: true
  remote_user: ansible
  vars_files:
    - vars/main.yml
  handlers:
    - import_tasks: handlers/main.yml

  tasks:
    # - name: Direct debug of vars
    #   ansible.builtin.debug:
    #     var: lookup('bitwarden.secrets.lookup', '63754df3-601f-4cfd-afac-b39300fa985e')

    # - name: Simple Debug
    #   ansible.builtin.debug:
    #     # msg: "CM Username: {{ lookup('bitwarden.secrets.lookup', lfs.cm_username) }}"
    #     var: lookup('bitwarden.secrets.lookup', lfs.cm_username)

    # - name: Debug Bitwarden Secrets
    #   ansible.builtin.debug:
    #     msg:
    #       - "CM Username: {{ lookup('bitwarden.secrets.lookup', vars['lfs']['cm_username']) }}"
    #       # - "CM Password: {{ lookup('bitwarden.secrets.lookup', vars['lfs']['cm_password']) }}"
    #       # - "K8s SSH User: {{ lookup('bitwarden.secrets.lookup', vars['k8s_ssh_user']) }}"
    #   when: true  # Set to true to enable debugging of Bitwarden secrets

    # Step 1
    - name: Check connectivity
      block:
        - name: Ping the hosts
          ansible.builtin.ping:

      # Step 2
    - name: Download & extract course materials
      block:
        # - name: Download course files
        #   ansible.builtin.get_url:
        #     url: https://cm.lf.training/LFS258/{{ course_docs_name }}.tar.xz
        #     url_password: "{{ lookup('bitwarden.secrets.lookup, vars['lfs']['cm_username']') }}"
        #     url_username: "{{ lookup('bitwarden.secrets.lookup, vars['lfs']['cm_password']') }}"
        #     dest: /tmp/{{ course_docs_name }}.tar.xz
        #     mode: "0644"
        #   register: course_files_download

        # - name: Debug LFS Credentials
        #   ansible.builtin.debug:
        #     msg:
        #       - "LFS CM Username: {{ lfs.cm_username }}"
        #       - "LFS CM Password: {{ lfs.cm_password }}"

        - name: Download course files
          ansible.builtin.get_url:
            url: https://cm.lf.training/LFS258/{{ course_docs_name }}.tar.xz
            url_password: "{{ lfs.cm_password }}"
            url_username: "{{ lfs.cm_username }}"
            dest: /tmp/{{ course_docs_name }}.tar.xz
            mode: "0644"
          register: course_files_download

        - name: Ensure /opt/course-docs directory exists
          ansible.builtin.file:
            path: "{{ course_docs_dir }}"
            state: directory
            mode: "0755"

        - name: Extract course docs
          ansible.builtin.unarchive:
            src: /tmp/{{ course_docs_name }}.tar.xz
            dest: "{{ course_docs_dir }}"
            remote_src: true
            extra_opts: [--strip-components=2]
          when: course_files_download.changed
          register: course_files_unarchive

        - name: Remove downloaded archive
          ansible.builtin.file:
            path: /tmp/{{ course_docs_name }}.tar.xz
            state: absent
          when: course_files_unarchive is successful

      # Step 4
    - name: Update & install pre-requisite packages
      block:
        - name: Update apt cache
          ansible.builtin.apt:
            update_cache: true
            cache_valid_time: 3600

        - name: Update system
          ansible.builtin.apt:
            upgrade: dist

        # Step 6
        - name: Install required packages
          ansible.builtin.apt:
            name:
              - apt-transport-https
              - bash-completion
              - ca-certificates
              - curl
              - gnupg
              - socat
              - software-properties-common
            state: present

      # Step 7
    - name: Perform OS-level setup
      block:
        - name: Disable swap
          ansible.builtin.command:
            cmd: swapoff -a
          when: ansible_swaptotal_mb | int > 0
          changed_when: true
          args:
            warn: false

        - name: Ensure swap is disabled in fstab
          ansible.builtin.replace:
            path: /etc/fstab
            regexp: '^([^#].*\sswap\s+)'
            replace: '# \1'
          register: swap_disabled

        - name: Report swap status
          ansible.builtin.debug:
            msg: >
              Swap disabled: {{ 'Yes' if swap_disabled.changed else 'No, already disabled' }}

      # Step 8
    - name: Load required modules & ensure loaded on boot
      block:
        - name: Load br_netfilter module
          ansible.builtin.modprobe:
            name: "{{ item }}"
            state: present
          loop:
            - br_netfilter
            - overlay

        - name: Ensure modules are loaded on boot
          ansible.builtin.copy:
            dest: /etc/modules-load.d/k8s.conf
            content: |
              br_netfilter
              overlay
            owner: root
            group: root
            mode: "0644"

      # Step 9
    - name: Configure kernel networking params for Kubernetes
      block:
        - name: Set kubernetes.conf from template
          ansible.builtin.template:
            src: kubernetes.conf.j2
            dest: /etc/sysctl.d/kubernetes.conf
            owner: root
            group: root
            mode: "0644"
          notify: Reload sysctl

        # Step 10
        - name: Apply sysctl params
          ansible.builtin.command:
            cmd: sysctl --system
          changed_when: false

      # Step 11
    - name: Prepare apt for containerd installation
      block:
        - name: Ensure apt keyrings directory exists
          ansible.builtin.file:
            path: "{{ keyrings_dir }}"
            state: directory
            mode: "0755"

        - name: Download Docker's GPG key to temp .asc file
          ansible.builtin.get_url:
            url: https://download.docker.com/linux/ubuntu/gpg
            dest: "{{ keyrings_dir }}/docker.asc"
            mode: "0644"
          register: docker_asc

        - name: Convert GPG key to dearmoured format
          ansible.builtin.command:
            cmd: gpg --dearmor -o "{{ keyrings_dir }}/docker.gpg" "{{ keyrings_dir }}/docker.asc"
          args:
            creates: "{{ keyrings_dir }}/docker.gpg"
          when: docker_asc.changed
          notify: Update apt cache

        - name: Normalise architecture fact
          # ansible_architecture returns x86_64 but apt expects amd64
          ansible.builtin.set_fact:
            apt_architecture: "{{ 'amd64' if ansible_architecture == 'x86_64' else ansible_architecture }}"

        - name: Add Docker apt repository
          ansible.builtin.apt_repository:
            repo: >
              deb [arch={{ apt_architecture }} signed-by=/etc/apt/keyrings/docker.gpg]
              https://download.docker.com/linux/ubuntu {{ ansible_lsb.codename }} stable
            filename: docker
            state: present
            update_cache: true

      # Step 12
    - name: Install & configure containerd
      block:
        - name: Check containerd.io availability
          ansible.builtin.apt:
            name: containerd.io
            state: present
            update_cache: true

        - name: Install containerd.io package
          ansible.builtin.apt:
            name: containerd.io
            state: present
            update_cache: true

        - name: Generate default containerd.io config file
          ansible.builtin.command:
            cmd: containerd config default
          register: containerd_default_config
          changed_when: false

        - name: Write containerd config file
          ansible.builtin.copy:
            dest: /etc/containerd/config.toml
            content: "{{ containerd_default_config.stdout }}"
            owner: root
            group: root
            mode: "0644"

        - name: Ensure containerd uses systemd cgroup driver
          ansible.builtin.lineinfile:
            path: /etc/containerd/config.toml
            regexp: '^\s*SystemdCgroup\s*='
            line: "SystemdCgroup = true"
            insertafter: '^\[plugins\."io.containerd.grpc.v1.cri"\]'

        - name: Restart containerd immediately to apply config changes
          ansible.builtin.systemd:
            name: containerd
            state: restarted
            enabled: true

    # Step 13
    - name: Prepare apt for Kubernetes installation
      block:
        - name: Download public signing key for K8s apt repo to temp asc file
          ansible.builtin.get_url:
            url: https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key
            dest: "{{ keyrings_dir }}/kubernetes-apt-key.asc"
            mode: "0644"
          register: k8s_apt_key_asc

        - name: Convert K8s GPG key to dearmoured format
          ansible.builtin.command:
            cmd: gpg --dearmor -o "{{ keyrings_dir }}/kubernetes-apt-keyring.gpg" "{{ keyrings_dir }}/kubernetes-apt-key.asc"
          args:
            creates: "{{ keyrings_dir }}/kubernetes-apt-key.gpg"
          when: k8s_apt_key_asc.changed
          notify: Update apt cache
          register: k8s_apt_key

        - name: Normalise architecture fact
          # ansible_architecture returns x86_64 but apt expects amd64
          ansible.builtin.set_fact:
            apt_architecture: "{{ 'amd64' if ansible_architecture == 'x86_64' else ansible_architecture }}"

        # Steps 14 & 15
        - name: Add Kubernetes apt repository
          ansible.builtin.apt_repository:
            repo: >
              deb [arch={{ apt_architecture }} signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg]
              https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /
            filename: kubernetes
            state: present
            update_cache: true

    - name: Install Kubernetes components
      block:
        # Step 16
        - name: Install Kubernetes components at specific versions
          ansible.builtin.apt:
            name:
              - "kubelet={{ kubernetes_version_apt }}"
              - "kubeadm={{ kubernetes_version_apt }}"
              - "kubectl={{ kubernetes_version_apt }}"
            state: present
            update_cache: true
            allow_downgrade: true
            force: yes
          notify: Update apt cache

        - name: Hold Kubernetes packages
          ansible.builtin.dpkg_selections:
            name: "{{ item }}"
            selection: hold
          loop:
            - kubelet
            - kubeadm
            - kubectl

    - name: IP Networking for K8s
      block:
        # Step 17
        - name: Obtain node primary IP address
          ansible.builtin.set_fact:
            node_primary_ip: "{{ ansible_default_ipv4.address }}"

    # Step 18
    - name: Add Kubernetes nodes to /etc/hosts
      ansible.builtin.blockinfile:
        path: /etc/hosts
        marker: "# {mark} ANSIBLE MANAGED K8S HOSTS"
        block: |
          {% set cp_nodes = groups.get('_control_plane', []) %}
          {% set worker_nodes = groups.get('_worker_node', []) %}
          {% set all_nodes = cp_nodes + worker_nodes %}

          {# Ensure that the host's own entry comes first #}
          {% for host in all_nodes if host == inventory_hostname %}
          {% if host in cp_nodes %}
          {{ hostvars[host].node_ip_internal | default(hostvars[host].ansible_default_ipv4.address) }} {{ host }} k8scp-{{ host.split('-')[-1] }} cp{{ host.split('-')[-1] }}
          {% else %}
          {{ hostvars[host].node_ip_internal | default(hostvars[host].ansible_default_ipv4.address) }} {{ host }} worker-{{ host.split('-')[-1] }} w{{ host.split('-')[-1] }}
          {% endif %}
          {% endfor %}

          {% for host in all_nodes if host != inventory_hostname %}
          {% if host in cp_nodes %}
          {{ hostvars[host].node_ip_internal | default(hostvars[host].ansible_default_ipv4.address) }} {{ host }} k8scp-{{ host.split('-')[-1] }} cp{{ host.split('-')[-1] }}
          {% elif host in worker_nodes %}
          {{ hostvars[host].node_ip_internal | default(hostvars[host].ansible_default_ipv4.address) }} {{ host }} worker-{{ host.split('-')[-1] }} w{{ host.split('-')[-1] }}
          {% endif %}
          {% endfor %}

    # Step 19
    - name: Initialize Kubernetes control plane
      block:
        - name: Set control plane IP fact from inventory
          ansible.builtin.set_fact:
            control_plane_ip: "{{ hostvars[groups['_control_plane'][0]].node_ip_internal | default(hostvars[groups['_control_plane'][0]].ansible_default_ipv4.address) }}"

        - name: Set control plane name fact
          ansible.builtin.set_fact:
            control_plane_name: "cp{{ inventory_hostname.split('-')[-1]}}"
          when: "'_control_plane' in group_names"

        - name: Check control plane IP
          ansible.builtin.debug:
            msg:
              - Control Plane IP is {{ control_plane_ip }}
              - Control Plane Name is {{ control_plane_name | default('not set for worker nodes') }}
          when: "'_control_plane' in group_names"

        - name: Create kubeadm config file from template on first control plane node
          ansible.builtin.template:
            src: kubeadm-config.yaml.j2
            dest: /root/kubeadm-config.yaml
            owner: root
            group: root
            mode: "0644"
          vars:
            control_plane_name: "cp{{ inventory_hostname.split('-')[-1]}}"
          when: inventory_hostname == groups['_control_plane'][0]

    # Step 20
    - name: Initialise K8s cluster with cp1 as control plane node
      block:
        - name: Flush handlers to ensure containerd is restarted before kubeadm init
          ansible.builtin.meta: flush_handlers
          # when: inventory_hostname == groups['_control_plane'][0]

        - name: Initialise Kubernetes control plane on first control plane node
          ansible.builtin.command:
            cmd: >
              kubeadm init
              --config=/root/kubeadm-config.yaml
              --upload-certs
              --node-name="{{ control_plane_name }}"
          args:
            creates: /etc/kubernetes/admin.conf
          when: inventory_hostname == groups['_control_plane'][0]
          register: kubeadm_init
          # TO-DO - write this to bws
          # notify: Save kubeadm outputs

        - name: Inspect kubeadm_init output
          ansible.builtin.debug:
            msg:
              - "Type: {{ kubeadm_init.stdout_lines | type_debug }}" # type of the registered variable
              - "Output length = {{ kubeadm_init.stdout_lines | length }}" # lines of output from kubeadm init
              - "First element type: {{ kubeadm_init.stdout_lines[0] | type_debug }}" # type of first element in stdout_lines
              - "{{ kubeadm_init.stdout_lines }}" # standard output from kubeadm init, formatted as a list of lines
              - "Errors = {{ kubeadm_init.stderr }}" # any error output from kubeadm init
              - "Command executed = {{ kubeadm_init.cmd }}" # command executed
              - "Return Code = {{ kubeadm_init.rc }}" # return code
              - "Changed = {{ kubeadm_init.changed }}" # whether the task reported a change
              - "Failure = {{ kubeadm_init.failed }}" # whether the task reported failure
              - "Start-time = {{ kubeadm_init.start }}" # timestamp when the task started
              - "End-time = {{ kubeadm_init.end }}" # timestamp when the task ended
              - "Task-duration = {{ kubeadm_init.delta }}" # duration of the task
          when: inventory_hostname == groups['_control_plane'][0] and kubeadm_init is defined

    - name: Extract worker join command from kubeadm_init output
      block:
        - name: Extract worker join command line-1 from kubeadm_init output (token)
          ansible.builtin.set_fact:
            kubeadm_worker_join_cmd_1: >-
              {{
                (
                  kubeadm_init.stdout_lines
                  | select('search', 'kubeadm join')
                  | list
                  | first
                  | regex_replace('\\$', '')
                  | trim
                )
              }}
          when: inventory_hostname == groups['_control_plane'][0] and kubeadm_init is defined

        - name: Extract worker join command line-2 from kubeadm_init output (ca-cert-hash)
          ansible.builtin.set_fact:
            kubeadm_worker_join_cmd_2: >-
              {{
                kubeadm_init.stdout_lines
                | select('search', '--discovery-token-ca-cert-hash')
                | map('trim')
                | map('regex_replace', '^.*(--discovery-token-ca-cert-hash\s+\S+).*$', '\1')
                | map('regex_replace', '--discovery-token-ca-cert-hash\s+', '')
                | first
              }}
          when: inventory_hostname == groups['_control_plane'][0] and kubeadm_init is defined

        - name: Debug line 1
          ansible.builtin.debug:
            msg: "Kubeadm join command line 1: {{ kubeadm_worker_join_cmd_1 }}"
          when: inventory_hostname == groups['_control_plane'][0] and kubeadm_init is defined

        - name: Debug line 2
          ansible.builtin.debug:
            msg: "Kubeadm join command line 2: {{ kubeadm_worker_join_cmd_2 }}"
          when: inventory_hostname == groups['_control_plane'][0] and kubeadm_init is defined

        - name: Combine join command and discovery hash into final join command
          ansible.builtin.set_fact:
            kubeadm_worker_join_cmd: "{{ kubeadm_worker_join_cmd_1 }} --discovery-token-ca-cert-hash {{ kubeadm_worker_join_cmd_2 }}"
          when:
            - inventory_hostname == groups['_control_plane'][0]
            - kubeadm_init is defined

        - name: Debug final kubeadm join command
          ansible.builtin.debug:
            msg: "Kubeadm join command: {{ kubeadm_worker_join_cmd }}"
          when: inventory_hostname == groups['_control_plane'][0] and kubeadm_init is defined

    # interstitial step: Share join command with worker nodes
    - name: Share kubeadm join command with worker nodes
      ansible.builtin.set_fact:
        kubeadm_worker_join_cmd: "{{ hostvars[groups['_control_plane'][0]].kubeadm_worker_join_cmd }}"
      when: "'_worker_node' in group_names"

    - name: Debug shared kubeadm join command on worker nodes
      ansible.builtin.debug:
        msg: "Shared kubeadm join command from worker: {{ kubeadm_worker_join_cmd }}"
      when: "'_worker_node' in group_names"

    # interstitial step: Join worker nodes to cluster
    - name: Join worker nodes to Kubernetes cluster
      block:
        - name: Check if kubelet is already joined to cluster
          ansible.builtin.stat:
            path: /etc/kubernetes/kubelet.conf
          register: kubelet_conf

        - name: Join worker node to cluster
          ansible.builtin.command:
            cmd: >
              {{ kubeadm_worker_join_cmd }} --node-name="worker-{{ inventory_hostname.split('-')[-1] }}"
          register: join_result
          when:
            - "'_worker_node' in group_names"
            - not kubelet_conf.stat.exists
          changed_when: >
            join_result.stdout is defined and
            'This node has joined the cluster' in join_result.stdout"

        - name: Report join status
          ansible.builtin.debug:
            msg: >
              Worker node {{ inventory_hostname }} join
              {{ 'succeeded' if join_result.changed else 'skipped, already joined' }}
          when: "'_worker_node' in group_names"

    # Step 21
    - name: Configure kubectl for non-root user on control plane node
      block:
        - name: Create .kube directory for ansible user
          ansible.builtin.file:
            dest: "/home/{{ k8s_ssh_user }}/.kube"
            state: directory
       # On remote control plane node only
        - name: Copy admin.conf to k8s_ssh_user's kube config
          ansible.builtin.copy:
            src: /etc/kubernetes/admin.conf
            dest: "/home/{{ k8s_ssh_user }}/.kube/config"
            owner: "{{ k8s_ssh_user }}"
            group: "{{ k8s_ssh_user }}"
            mode: "0600"
            remote_src: true
          when: inventory_hostname == groups['_control_plane'][0]

        # Copy to local workstation for kubectl use
        - name: Save kubeconfig locally
          ansible.builtin.fetch:
            src: "/etc/kubernetes/admin.conf"
            dest: "{{ playbook_dir }}/outputs/kubeconfig"
            flat: true
          run_once: true
          become: true
          when: inventory_hostname == groups['_control_plane'][0]

    # Step 22
    - name: Install a CNI plugin (Cilium) on control plane node
      block:
        - name: Render Cilium CNI manifest to file from template on CP node
          ansible.builtin.template:
            src: cilium-cni.yaml.j2
            dest: /root/cilium-cni.yaml
            owner: root
            group: root
            mode: "0644"
          run_once: true
          when: inventory_hostname == groups['_control_plane'][0]

    - name: Install Cilium CNI on control plane node
      ansible.builtin.command:
        cmd: >
          kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /root/cilium-cni.yaml
      when: inventory_hostname == groups['_control_plane'][0]

    - name: Wait for Cilium pods to be ready
      ansible.builtin.command:
        cmd: >
          kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system rollout status ds/cilium
      become: true
      retries: 10
      delay: 15
      register: cilium_rollout
      until: cilium_rollout.rc == 0
      run_once: true
      when: inventory_hostname == groups['_control_plane'][0]

   # Step 23
    - name: Enable bash completion for kubectl for k8s_ssh_user
      block:
        - name: Ensure bash completion package is installed
          ansible.builtin.apt:
            name: bash-completion
            state: present
            update_cache: true

    - name: Add kubectl bash completion to k8s_ssh_user's .bashrc
      ansible.builtin.lineinfile:
        path: "/home/{{ k8s_ssh_user }}/.bashrc"
        line: "source <(kubectl completion bash)"
        insertafter: EOF
        state: present
        create: true
        owner: "{{ k8s_ssh_user }}"
        group: "{{ k8s_ssh_user }}"
      become: true
      when: k8s_ssh_user is defined and k8s_ssh_user != 'root'

    - name: Source the updated .bashrc to enable kubectl completion
      ansible.builtin.shell:
        cmd: "source <(kubectl completion bash)"
      args:
        executable: /bin/bash
      become: true
      when: k8s_ssh_user is defined and k8s_ssh_user != 'root'

  # End of playbook
